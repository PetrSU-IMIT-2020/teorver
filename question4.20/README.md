# Билет №4.20. Линейная регрессия.

> *В регрессивном анализе рассматривается связь между зависимой величиной Y и одной или несколькими независимыми выличинами X. При этом Х принимает фиксированные значения, а У имеет случайный разброс по каким-либо причинам. Каждому знаению Х соответствует какое-то вероятностное распределение случайной величины У. Предпологается, что У "в среднем" линейно зависит от Х*

## Формула

Раз У линейно зависит от X, то условное математическое ожидание Y при значении x имеет следующий вид:

$M[Y|\_{x}] = \beta_0 + \beta_1 * x$

Правая часть уравнения называется линейной регрессией Y на x. Параметры $\beta_0\ и\ \beta_1$ заранее неизвестны и находятся по результатам измерений перменных Y на X.

## Линейная регрессионная модель

- $\sigma$ - среднее квадратическое отклонение
 
Пусть провеедно n независимых наблюдений Y при значениях x = $x_1,x_2,...,x_n$ при этом измерения Y дали следующие результаты y = $y_1,y_2,...,y_n$. Т.к. эти значения имеют разброс относительно линейной регрессии, то связь между переменными Y и X можно записать в виде *линейной регрессионной модели*:

$\displaystyle Y = \beta_0 + \beta_1 * x + \xi$

Где $\xi$ - случайная ошибка измерений, причём предпологается, что $M[\xi]$ = 0, $D[\xi] = \sigma^2$.

## Нахождение параметров линейной регрессонной модели

Для нахождения параметров $\beta_0, \beta_1$ используется метод наименьших квадратов. Поэтому подбираются такие параметры, которые минимизируют сумму квадратов отклонений наблюдаемой величины Yi, i = 1..n. от их математических ожиданий. Т.е. сумму:

$\displaystyle Q(\beta_0, \beta_1) = \sum\limits_{i = 1}^{n} (y_i - (\beta_0 + \beta_1 * x_i))$

Из необходимых условий минимума функции Q получим:

$\displaystyle \frac{\delta Q}{\delta\beta_0} = \frac{\delta Q}{\delta\beta_1} = 0$

Получим:

$\displaystyle \beta_1 = \frac{\sum x_iy_i - \frac{1}{n}(\sum x_i)(\sum y_i)}{\sum x_i^2 - \frac{1}{n}(\sum x_i)^2} = \frac{\sum (x_i - \overset{-}{x})(y_i - \overset{-}{y})}{\sum (x_i - \overset{-}{x})^2} = \frac{Q_{xy}}{Q_x}$

- $\overset{-}{x} = \frac{1}{n}\sum x_i$
- $\overset{-}{y} = \frac{1}{n}\sum y_i$
- $Q_{xy} = \sum (x_i - \overset{-}{x})(y_i - \overset{-}{y})$
- $Q_x = \sum (x_i - \overset{-}{x})^2$

$\displaystyle \beta_0 = \overset{-}{y} - \beta_1 \overset{-}{x}$

---
## Создатель

Автор расписанного билета: Курочкин Дима

Кто проверил:
- 

## Ресурсы
- [Учебник Рогова](https://studizba.com/files/show/pdf/18027-4-4-chast.html), страница 298
